###### Dataset and Network ######
dataset: 'CIFAR10' # options: CIFAR100, CIFAR10, ImageNet
network: 'DASNet34' # options: DASNet34, DARTS, DARTSPlus
num_cells: 14 # options: 7, 14, 20

### CONet Settings ###
full_train_only: False #False = search + train, #True = train only using the channel sizes in global_vars.py

###### Channel Search Training Hyperparameters ######
init_lr: 0.03 # Recommend 0.1 for DARTS/DARTS+, 0.03 for ResNet34
lr_scheduler: 'AdaS' # options: AdaS (with SGD), StepLR. Recommend AdaS
beta: 0.8 # recommend 0.8
adapt_trials: 25 # Recommend 25
epochs_per_trial: 20 # Recommend 20
mapping_condition_threshold: 10  #Recommend 10.
delta_threshold: 0.0075 #Recommend 0.0025, 0.005, 0.0075, 0.01, 0.015 ...
delta_threshold_values:
  - 0.0075
max_conv_size: 256 # Recommend 256
min_conv_size: 16 # Recommend 16 for DARTS/DARTS+, 32 for ResNet34
min_scale_limit: 0.01 # Recommend
factor_scale: 0.2 # Recommend 0.2

mini_batch_size: 128 # Recommend 128
weight_decay: 5e-4 #Recommend 5e-4

# Enable auxiliary tower - DARTS/DARTS+ only
auxiliary: False # Recommend False
# Enable drop path between conv layers - DARTS/DARTS+ only
drop_path: False # Recommend False
# Enable gradient clipping - DARTS/DARTS+ only
grad_clip: False # Recommend False
# Enable cutout for CIFAR/
cutout: False # Recommend False


###### Full Train/Model Evaluation Hyperparameters ######
max_epoch: 250 # 250 for CIFAR,  200 For ImageNet
mini_batch_size_full: 128 # Recommend 128 for ResNet, 96 for DARTS/DARTS+
weight_decay_full: 3e-4 # Recommend 3e-4 for CIFAR DARTS/DARTSPLUS, 3e-5 for ImageNet DARTS/DARTS+, 5e-4 for ResNet34
lr_scheduler_full: 'StepLR' # options: AdaS (with SGD), StepLR. Recommend StepLR
init_lr_full: 0.1
beta_full: 0.95

# Enable auxiliary tower - DARTS/DARTS+ only
auxiliary_full: True # Recommend True
# Enable drop path between conv layers - DARTS/DARTS+ only
drop_path_full: True # Recommend True for CIFAR, False for ImageNet
# Enable gradient clipping - DARTS/DARTS+ only
grad_clip_full: True # Recommend True
# Enable cutout for CIFAR/
cutout_full: True # Recommend True


##### Additional AdaS LR scheduler settings #####
min_lr: 0.00000000000000000001
zeta: 1.0
p: 1 # options: 1, 2.

##### Additional StepLR settings #####
step_size: 25 #Default 25
gamma: 0.5 #Default 0.5

########################### Settings below this point are recommended defaults ###########################
### Suggested Default Settings ###
optim_method: 'SGD' # options: SGD
loss: 'cross_entropy' # options: cross_entropy
early_stop_threshold: -1 # set to -1 if you wish not to use early stop, or equally, set to a high value. Set to -1 if not using AdaS
early_stop_patience: 10 # epoch window to consider when deciding whether to stop
train_num: 1 # options >= 0. If it is set to 0 or 1, run full train only once. Else run full train n times
# Axuiliary Tower weight - DARTS/DARTS+ only
auxiliary_weight: 0.4 #default 0.4
# Drop path probability - DARTS/DARTS+ only
drop_path_prob: 0.2 #default 0.2
# Grad clip threshold DARTS/DARTS+ only
grad_clip_threshold: 5 #Default 5
# Cutout length for CIFAR10/CIFAR100
cutout_length: 16
# Label smoothing for ImageNet
label_smooth: 0.1

# for file naming uniqueness purposes, but MUST to be ints separated by commas "1,2,3,4", NO strings/characters
init_conv_setting: '3,3'

### Unused Settings ###
# These settings are from earlier implementations of CONet
adapt_trials_kernel: 0
delta_threshold_kernel: 0.75 #This is a percentage, 0.25, 0.5, 0.75
delta_threshold_kernel_values:
  - 0.75
kernel_adapt: 0 #0 for NO kernel adaptations, 1 for kernel adaptions
parameter_type: 'channel' #'both' for simultaneously searching kernel and conv, else 'channel' for consecutive channel/kernel search
factor_scale_kernel: 1
blocks_per_superblock: -1 #set to -1 for DasNet34 structure, 2 for all 2s, 3 for all 3s
stable_epoch: 0
max_kernel_size: 9
min_kernel_size: 1
min_kernel_size_2: 1